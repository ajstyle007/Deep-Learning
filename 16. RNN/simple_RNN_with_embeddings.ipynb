{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c1205373-ed72-4f9a-9999-232b53194e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4a4440ec-64b2-40c1-9c5f-e1d8d6017da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f2a54a19-dedd-4b7d-b4ec-d53009288c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d7016794-4aca-4c7c-9946-34f5731f9799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0faaea-3d81-4720-86e5-868c81dc8ab7",
   "metadata": {},
   "source": [
    "## Step 2: Preprocessing (Tokenization & Vocabulary Building)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f483d2-409d-44ad-9480-4c6a65dc6e57",
   "metadata": {},
   "source": [
    "- We'll convert text into numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "27223774-35b1-440b-a565-2b0375b01e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "023c6b7a-c4b0-4407-abad-3afe4d1d31ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can also use the above library but we will use the basics of NLP for text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f523ef16-259b-4624-89ce-a81aa1b5ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "04397c19-17ee-4d1c-b934-9355f2497062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3dd39839-04b4-4cfd-94b9-3ae83dffd05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stopwords and stemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6358078d-0d3d-4ba7-8d7f-b39c7e76ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "# to understand this function visit the another notebook\n",
    "def tokenize(text):\n",
    "  text = text.lower()\n",
    "  text = text.replace('?','')\n",
    "  text = text.replace(\"'\",\"\")\n",
    "  return text.split()\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove non-alphabetic characters (punctuation, etc.)\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and apply stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d717d254-9a7e-4c6d-8be1-ce866700d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to the review column\n",
    "df['tokens'] = df['review'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3bd28ad7-f3f7-4810-b775-2334fccbf850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, review, mention, watch, 1, oz, episod, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wonder, littl, product, br, br, film, techniq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonder, way, spend, time, hot, summe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basic, famili, littl, boy, jake, think, zombi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, mattei, love, time, money, visual, st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                              tokens  \n",
       "0  [one, review, mention, watch, 1, oz, episod, h...  \n",
       "1  [wonder, littl, product, br, br, film, techniq...  \n",
       "2  [thought, wonder, way, spend, time, hot, summe...  \n",
       "3  [basic, famili, littl, boy, jake, think, zombi...  \n",
       "4  [petter, mattei, love, time, money, visual, st...  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "90d79f48-b022-4413-bf7c-93983b56da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the Vocabulary\n",
    "\n",
    "\"\"\" \n",
    "'<UNK>' (short for Unknown) is a special token used to represent out-of-vocabulary (OOV) \n",
    "words—words that are not found in the training vocabulary.\n",
    "\n",
    "The dictionary initializes '<UNK>' with an index of 0. This means that any word that is not in the vocabulary\n",
    "will be replaced with this special token and assigned index 0.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "vocab = {'<UNK>': 0}  # Add <UNK> for unknown words\n",
    "\n",
    "# Function to build the vocabulary\n",
    "def build_vocab(row):\n",
    "    tokens = row['tokens']# Get tokenized review\n",
    "    \n",
    "    for token in tokens:  # Iterate through tokens in the review\n",
    "        if token not in vocab:  # If token is not already in vocab\n",
    "            vocab[token] = len(vocab)  # Assign it a unique index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e681c08c-a621-45aa-acc2-3330e4d6ab97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "49995    None\n",
       "49996    None\n",
       "49997    None\n",
       "49998    None\n",
       "49999    None\n",
       "Length: 50000, dtype: object"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to each row of the dataframe\n",
    "df.apply(build_vocab, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "764810b4-5836-4b2b-9fe5-d24fb4efbb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<UNK>': 0,\n",
       " 'one': 1,\n",
       " 'review': 2,\n",
       " 'mention': 3,\n",
       " 'watch': 4,\n",
       " '1': 5,\n",
       " 'oz': 6,\n",
       " 'episod': 7,\n",
       " 'hook': 8,\n",
       " 'right': 9,\n",
       " 'exactli': 10,\n",
       " 'happen': 11,\n",
       " 'br': 12,\n",
       " 'first': 13,\n",
       " 'thing': 14,\n",
       " 'struck': 15,\n",
       " 'brutal': 16,\n",
       " 'unflinch': 17,\n",
       " 'scene': 18,\n",
       " 'violenc': 19,\n",
       " 'set': 20,\n",
       " 'word': 21,\n",
       " 'go': 22,\n",
       " 'trust': 23,\n",
       " 'show': 24,\n",
       " 'faint': 25,\n",
       " 'heart': 26,\n",
       " 'timid': 27,\n",
       " 'pull': 28,\n",
       " 'punch': 29,\n",
       " 'regard': 30,\n",
       " 'drug': 31,\n",
       " 'sex': 32,\n",
       " 'hardcor': 33,\n",
       " 'classic': 34,\n",
       " 'use': 35,\n",
       " 'call': 36,\n",
       " 'nicknam': 37,\n",
       " 'given': 38,\n",
       " 'oswald': 39,\n",
       " 'maximum': 40,\n",
       " 'secur': 41,\n",
       " 'state': 42,\n",
       " 'penitentari': 43,\n",
       " 'focus': 44,\n",
       " 'mainli': 45,\n",
       " 'emerald': 46,\n",
       " 'citi': 47,\n",
       " 'experiment': 48,\n",
       " 'section': 49,\n",
       " 'prison': 50,\n",
       " 'cell': 51,\n",
       " 'glass': 52,\n",
       " 'front': 53,\n",
       " 'face': 54,\n",
       " 'inward': 55,\n",
       " 'privaci': 56,\n",
       " 'high': 57,\n",
       " 'agenda': 58,\n",
       " 'em': 59,\n",
       " 'home': 60,\n",
       " 'mani': 61,\n",
       " 'aryan': 62,\n",
       " 'muslim': 63,\n",
       " 'gangsta': 64,\n",
       " 'latino': 65,\n",
       " 'christian': 66,\n",
       " 'italian': 67,\n",
       " 'irish': 68,\n",
       " 'scuffl': 69,\n",
       " 'death': 70,\n",
       " 'stare': 71,\n",
       " 'dodgi': 72,\n",
       " 'deal': 73,\n",
       " 'shadi': 74,\n",
       " 'agreement': 75,\n",
       " 'never': 76,\n",
       " 'far': 77,\n",
       " 'away': 78,\n",
       " 'would': 79,\n",
       " 'say': 80,\n",
       " 'main': 81,\n",
       " 'appeal': 82,\n",
       " 'due': 83,\n",
       " 'fact': 84,\n",
       " 'goe': 85,\n",
       " 'dare': 86,\n",
       " 'forget': 87,\n",
       " 'pretti': 88,\n",
       " 'pictur': 89,\n",
       " 'paint': 90,\n",
       " 'mainstream': 91,\n",
       " 'audienc': 92,\n",
       " 'charm': 93,\n",
       " 'romanc': 94,\n",
       " 'mess': 95,\n",
       " 'around': 96,\n",
       " 'ever': 97,\n",
       " 'saw': 98,\n",
       " 'nasti': 99,\n",
       " 'surreal': 100,\n",
       " 'readi': 101,\n",
       " 'develop': 102,\n",
       " 'tast': 103,\n",
       " 'got': 104,\n",
       " 'accustom': 105,\n",
       " 'level': 106,\n",
       " 'graphic': 107,\n",
       " 'injustic': 108,\n",
       " 'crook': 109,\n",
       " 'guard': 110,\n",
       " 'sold': 111,\n",
       " 'nickel': 112,\n",
       " 'inmat': 113,\n",
       " 'kill': 114,\n",
       " 'order': 115,\n",
       " 'get': 116,\n",
       " 'well': 117,\n",
       " 'manner': 118,\n",
       " 'middl': 119,\n",
       " 'class': 120,\n",
       " 'turn': 121,\n",
       " 'bitch': 122,\n",
       " 'lack': 123,\n",
       " 'street': 124,\n",
       " 'skill': 125,\n",
       " 'experi': 126,\n",
       " 'may': 127,\n",
       " 'becom': 128,\n",
       " 'comfort': 129,\n",
       " 'uncomfort': 130,\n",
       " 'view': 131,\n",
       " 'that': 132,\n",
       " 'touch': 133,\n",
       " 'darker': 134,\n",
       " 'side': 135,\n",
       " 'wonder': 136,\n",
       " 'littl': 137,\n",
       " 'product': 138,\n",
       " 'film': 139,\n",
       " 'techniqu': 140,\n",
       " 'unassum': 141,\n",
       " 'old': 142,\n",
       " 'time': 143,\n",
       " 'bbc': 144,\n",
       " 'fashion': 145,\n",
       " 'give': 146,\n",
       " 'sometim': 147,\n",
       " 'discomfort': 148,\n",
       " 'sens': 149,\n",
       " 'realism': 150,\n",
       " 'entir': 151,\n",
       " 'piec': 152,\n",
       " 'actor': 153,\n",
       " 'extrem': 154,\n",
       " 'chosen': 155,\n",
       " 'michael': 156,\n",
       " 'sheen': 157,\n",
       " 'polari': 158,\n",
       " 'voic': 159,\n",
       " 'pat': 160,\n",
       " 'truli': 161,\n",
       " 'see': 162,\n",
       " 'seamless': 163,\n",
       " 'edit': 164,\n",
       " 'guid': 165,\n",
       " 'refer': 166,\n",
       " 'william': 167,\n",
       " 'diari': 168,\n",
       " 'entri': 169,\n",
       " 'worth': 170,\n",
       " 'terrificli': 171,\n",
       " 'written': 172,\n",
       " 'perform': 173,\n",
       " 'master': 174,\n",
       " 'great': 175,\n",
       " 'comedi': 176,\n",
       " 'life': 177,\n",
       " 'realli': 178,\n",
       " 'come': 179,\n",
       " 'fantasi': 180,\n",
       " 'rather': 181,\n",
       " 'tradit': 182,\n",
       " 'dream': 183,\n",
       " 'remain': 184,\n",
       " 'solid': 185,\n",
       " 'disappear': 186,\n",
       " 'play': 187,\n",
       " 'knowledg': 188,\n",
       " 'particularli': 189,\n",
       " 'concern': 190,\n",
       " 'orton': 191,\n",
       " 'halliwel': 192,\n",
       " 'flat': 193,\n",
       " 'mural': 194,\n",
       " 'decor': 195,\n",
       " 'everi': 196,\n",
       " 'surfac': 197,\n",
       " 'terribl': 198,\n",
       " 'done': 199,\n",
       " 'thought': 200,\n",
       " 'way': 201,\n",
       " 'spend': 202,\n",
       " 'hot': 203,\n",
       " 'summer': 204,\n",
       " 'weekend': 205,\n",
       " 'sit': 206,\n",
       " 'air': 207,\n",
       " 'condit': 208,\n",
       " 'theater': 209,\n",
       " 'light': 210,\n",
       " 'plot': 211,\n",
       " 'simplist': 212,\n",
       " 'dialogu': 213,\n",
       " 'witti': 214,\n",
       " 'charact': 215,\n",
       " 'likabl': 216,\n",
       " 'even': 217,\n",
       " 'bread': 218,\n",
       " 'suspect': 219,\n",
       " 'serial': 220,\n",
       " 'killer': 221,\n",
       " 'disappoint': 222,\n",
       " 'realiz': 223,\n",
       " 'match': 224,\n",
       " 'point': 225,\n",
       " '2': 226,\n",
       " 'risk': 227,\n",
       " 'addict': 228,\n",
       " 'proof': 229,\n",
       " 'woodi': 230,\n",
       " 'allen': 231,\n",
       " 'still': 232,\n",
       " 'fulli': 233,\n",
       " 'control': 234,\n",
       " 'style': 235,\n",
       " 'us': 236,\n",
       " 'grown': 237,\n",
       " 'love': 238,\n",
       " 'laugh': 239,\n",
       " 'year': 240,\n",
       " 'decad': 241,\n",
       " 'impress': 242,\n",
       " 'scarlet': 243,\n",
       " 'johanson': 244,\n",
       " 'manag': 245,\n",
       " 'tone': 246,\n",
       " 'sexi': 247,\n",
       " 'imag': 248,\n",
       " 'jump': 249,\n",
       " 'averag': 250,\n",
       " 'spirit': 251,\n",
       " 'young': 252,\n",
       " 'woman': 253,\n",
       " 'crown': 254,\n",
       " 'jewel': 255,\n",
       " 'career': 256,\n",
       " 'wittier': 257,\n",
       " 'devil': 258,\n",
       " 'wear': 259,\n",
       " 'prada': 260,\n",
       " 'interest': 261,\n",
       " 'superman': 262,\n",
       " 'friend': 263,\n",
       " 'basic': 264,\n",
       " 'famili': 265,\n",
       " 'boy': 266,\n",
       " 'jake': 267,\n",
       " 'think': 268,\n",
       " 'zombi': 269,\n",
       " 'closet': 270,\n",
       " 'parent': 271,\n",
       " 'fight': 272,\n",
       " 'movi': 273,\n",
       " 'slower': 274,\n",
       " 'soap': 275,\n",
       " 'opera': 276,\n",
       " 'suddenli': 277,\n",
       " 'decid': 278,\n",
       " 'rambo': 279,\n",
       " 'ok': 280,\n",
       " 'make': 281,\n",
       " 'must': 282,\n",
       " 'thriller': 283,\n",
       " 'drama': 284,\n",
       " 'watchabl': 285,\n",
       " 'divorc': 286,\n",
       " 'argu': 287,\n",
       " 'like': 288,\n",
       " 'real': 289,\n",
       " 'total': 290,\n",
       " 'ruin': 291,\n",
       " 'expect': 292,\n",
       " 'boogeyman': 293,\n",
       " 'similar': 294,\n",
       " 'instead': 295,\n",
       " 'meaningless': 296,\n",
       " 'spot': 297,\n",
       " '3': 298,\n",
       " '10': 299,\n",
       " 'descent': 300,\n",
       " 'dialog': 301,\n",
       " 'shot': 302,\n",
       " 'ignor': 303,\n",
       " 'petter': 304,\n",
       " 'mattei': 305,\n",
       " 'money': 306,\n",
       " 'visual': 307,\n",
       " 'stun': 308,\n",
       " 'mr': 309,\n",
       " 'offer': 310,\n",
       " 'vivid': 311,\n",
       " 'portrait': 312,\n",
       " 'human': 313,\n",
       " 'relat': 314,\n",
       " 'seem': 315,\n",
       " 'tell': 316,\n",
       " 'power': 317,\n",
       " 'success': 318,\n",
       " 'peopl': 319,\n",
       " 'differ': 320,\n",
       " 'situat': 321,\n",
       " 'encount': 322,\n",
       " 'variat': 323,\n",
       " 'arthur': 324,\n",
       " 'schnitzler': 325,\n",
       " 'theme': 326,\n",
       " 'director': 327,\n",
       " 'transfer': 328,\n",
       " 'action': 329,\n",
       " 'present': 330,\n",
       " 'new': 331,\n",
       " 'york': 332,\n",
       " 'meet': 333,\n",
       " 'connect': 334,\n",
       " 'anoth': 335,\n",
       " 'next': 336,\n",
       " 'person': 337,\n",
       " 'know': 338,\n",
       " 'previou': 339,\n",
       " 'contact': 340,\n",
       " 'stylishli': 341,\n",
       " 'sophist': 342,\n",
       " 'luxuri': 343,\n",
       " 'look': 344,\n",
       " 'taken': 345,\n",
       " 'live': 346,\n",
       " 'world': 347,\n",
       " 'habitat': 348,\n",
       " 'soul': 349,\n",
       " 'stage': 350,\n",
       " 'loneli': 351,\n",
       " 'inhabit': 352,\n",
       " 'big': 353,\n",
       " 'best': 354,\n",
       " 'place': 355,\n",
       " 'find': 356,\n",
       " 'sincer': 357,\n",
       " 'fulfil': 358,\n",
       " 'discern': 359,\n",
       " 'case': 360,\n",
       " 'act': 361,\n",
       " 'good': 362,\n",
       " 'direct': 363,\n",
       " 'steve': 364,\n",
       " 'buscemi': 365,\n",
       " 'rosario': 366,\n",
       " 'dawson': 367,\n",
       " 'carol': 368,\n",
       " 'kane': 369,\n",
       " 'imperioli': 370,\n",
       " 'adrian': 371,\n",
       " 'grenier': 372,\n",
       " 'rest': 373,\n",
       " 'talent': 374,\n",
       " 'cast': 375,\n",
       " 'aliv': 376,\n",
       " 'wish': 377,\n",
       " 'luck': 378,\n",
       " 'await': 379,\n",
       " 'anxious': 380,\n",
       " 'work': 381,\n",
       " 'probabl': 382,\n",
       " 'favorit': 383,\n",
       " 'stori': 384,\n",
       " 'selfless': 385,\n",
       " 'sacrific': 386,\n",
       " 'dedic': 387,\n",
       " 'nobl': 388,\n",
       " 'caus': 389,\n",
       " 'preachi': 390,\n",
       " 'bore': 391,\n",
       " 'despit': 392,\n",
       " 'seen': 393,\n",
       " '15': 394,\n",
       " 'last': 395,\n",
       " '25': 396,\n",
       " 'paul': 397,\n",
       " 'luka': 398,\n",
       " 'bring': 399,\n",
       " 'tear': 400,\n",
       " 'eye': 401,\n",
       " 'bett': 402,\n",
       " 'davi': 403,\n",
       " 'sympathet': 404,\n",
       " 'role': 405,\n",
       " 'delight': 406,\n",
       " 'kid': 407,\n",
       " 'grandma': 408,\n",
       " 'dress': 409,\n",
       " 'midget': 410,\n",
       " 'children': 411,\n",
       " 'fun': 412,\n",
       " 'mother': 413,\n",
       " 'slow': 414,\n",
       " 'awaken': 415,\n",
       " 'roof': 416,\n",
       " 'believ': 417,\n",
       " 'startl': 418,\n",
       " 'dozen': 419,\n",
       " 'thumb': 420,\n",
       " 'sure': 421,\n",
       " 'resurrect': 422,\n",
       " 'date': 423,\n",
       " 'seahunt': 424,\n",
       " 'seri': 425,\n",
       " 'tech': 426,\n",
       " 'today': 427,\n",
       " 'back': 428,\n",
       " 'excit': 429,\n",
       " 'grew': 430,\n",
       " 'black': 431,\n",
       " 'white': 432,\n",
       " 'tv': 433,\n",
       " 'gunsmok': 434,\n",
       " 'hero': 435,\n",
       " 'week': 436,\n",
       " 'vote': 437,\n",
       " 'comeback': 438,\n",
       " 'sea': 439,\n",
       " 'hunt': 440,\n",
       " 'need': 441,\n",
       " 'chang': 442,\n",
       " 'pace': 443,\n",
       " 'water': 444,\n",
       " 'adventur': 445,\n",
       " 'oh': 446,\n",
       " 'thank': 447,\n",
       " 'outlet': 448,\n",
       " 'viewpoint': 449,\n",
       " 'ole': 450,\n",
       " 'wan': 451,\n",
       " 'na': 452,\n",
       " 'nice': 453,\n",
       " 'read': 454,\n",
       " 'plu': 455,\n",
       " 'rhyme': 456,\n",
       " 'line': 457,\n",
       " 'let': 458,\n",
       " 'submit': 459,\n",
       " 'leav': 460,\n",
       " 'doubt': 461,\n",
       " 'quit': 462,\n",
       " 'amaz': 463,\n",
       " 'fresh': 464,\n",
       " 'innov': 465,\n",
       " 'idea': 466,\n",
       " '70': 467,\n",
       " '7': 468,\n",
       " '8': 469,\n",
       " 'brilliant': 470,\n",
       " 'drop': 471,\n",
       " '1990': 472,\n",
       " 'funni': 473,\n",
       " 'anymor': 474,\n",
       " 'continu': 475,\n",
       " 'declin': 476,\n",
       " 'complet': 477,\n",
       " 'wast': 478,\n",
       " 'disgrac': 479,\n",
       " 'fallen': 480,\n",
       " 'write': 481,\n",
       " 'pain': 482,\n",
       " 'bad': 483,\n",
       " 'almost': 484,\n",
       " 'mildli': 485,\n",
       " 'entertain': 486,\n",
       " 'respit': 487,\n",
       " 'guest': 488,\n",
       " 'host': 489,\n",
       " 'hard': 490,\n",
       " 'creator': 491,\n",
       " 'hand': 492,\n",
       " 'select': 493,\n",
       " 'origin': 494,\n",
       " 'also': 495,\n",
       " 'chose': 496,\n",
       " 'band': 497,\n",
       " 'hack': 498,\n",
       " 'follow': 499,\n",
       " 'recogn': 500,\n",
       " 'brillianc': 501,\n",
       " 'fit': 502,\n",
       " 'replac': 503,\n",
       " 'mediocr': 504,\n",
       " 'felt': 505,\n",
       " 'star': 506,\n",
       " 'respect': 507,\n",
       " 'made': 508,\n",
       " 'huge': 509,\n",
       " 'aw': 510,\n",
       " 'encourag': 511,\n",
       " 'posit': 512,\n",
       " 'comment': 513,\n",
       " 'forward': 514,\n",
       " 'mistak': 515,\n",
       " '950': 516,\n",
       " 'worst': 517,\n",
       " 'storylin': 518,\n",
       " 'soundtrack': 519,\n",
       " 'song': 520,\n",
       " 'lame': 521,\n",
       " 'countri': 522,\n",
       " 'tune': 523,\n",
       " 'less': 524,\n",
       " 'four': 525,\n",
       " 'cheap': 526,\n",
       " 'rare': 527,\n",
       " 'happi': 528,\n",
       " 'end': 529,\n",
       " 'credit': 530,\n",
       " 'prevent': 531,\n",
       " 'score': 532,\n",
       " 'harvey': 533,\n",
       " 'keitel': 534,\n",
       " 'least': 535,\n",
       " 'bit': 536,\n",
       " 'effort': 537,\n",
       " 'obsess': 538,\n",
       " 'gut': 539,\n",
       " 'wrench': 540,\n",
       " 'laughter': 541,\n",
       " 'hell': 542,\n",
       " 'mom': 543,\n",
       " 'camp': 544,\n",
       " 'phil': 545,\n",
       " 'alien': 546,\n",
       " 'quirki': 547,\n",
       " 'humour': 548,\n",
       " 'base': 549,\n",
       " 'odd': 550,\n",
       " 'everyth': 551,\n",
       " 'actual': 552,\n",
       " 'punchlin': 553,\n",
       " 'progress': 554,\n",
       " 'joke': 555,\n",
       " 'low': 556,\n",
       " 'budget': 557,\n",
       " 'problem': 558,\n",
       " 'eventu': 559,\n",
       " 'lost': 560,\n",
       " 'imagin': 561,\n",
       " 'stoner': 562,\n",
       " 'current': 563,\n",
       " 'partak': 564,\n",
       " 'someth': 565,\n",
       " 'better': 566,\n",
       " 'tri': 567,\n",
       " 'brother': 568,\n",
       " 'planet': 569,\n",
       " '12': 570,\n",
       " 'came': 571,\n",
       " 'recal': 572,\n",
       " 'scariest': 573,\n",
       " 'bird': 574,\n",
       " 'eat': 575,\n",
       " 'men': 576,\n",
       " 'dangl': 577,\n",
       " 'helplessli': 578,\n",
       " 'parachut': 579,\n",
       " 'horror': 580,\n",
       " 'cheesi': 581,\n",
       " 'b': 582,\n",
       " 'saturday': 583,\n",
       " 'afternoon': 584,\n",
       " 'tire': 585,\n",
       " 'formula': 586,\n",
       " 'monster': 587,\n",
       " 'type': 588,\n",
       " 'usual': 589,\n",
       " 'includ': 590,\n",
       " 'beauti': 591,\n",
       " 'might': 592,\n",
       " 'daughter': 593,\n",
       " 'professor': 594,\n",
       " 'resolut': 595,\n",
       " 'die': 596,\n",
       " 'care': 597,\n",
       " 'much': 598,\n",
       " 'romant': 599,\n",
       " 'angl': 600,\n",
       " 'predict': 601,\n",
       " 'unintent': 602,\n",
       " 'humor': 603,\n",
       " 'later': 604,\n",
       " 'psycho': 605,\n",
       " 'janet': 606,\n",
       " 'leigh': 607,\n",
       " 'bump': 608,\n",
       " 'earli': 609,\n",
       " 'sat': 610,\n",
       " 'took': 611,\n",
       " 'notic': 612,\n",
       " 'sinc': 613,\n",
       " 'screenwrit': 614,\n",
       " 'scari': 615,\n",
       " 'possibl': 616,\n",
       " 'worn': 617,\n",
       " 'rule': 618,\n",
       " 'im': 619,\n",
       " 'fan': 620,\n",
       " 'boll': 621,\n",
       " 'enjoy': 622,\n",
       " 'postal': 623,\n",
       " 'mayb': 624,\n",
       " 'appar': 625,\n",
       " 'bought': 626,\n",
       " 'cri': 627,\n",
       " 'long': 628,\n",
       " 'ago': 629,\n",
       " 'game': 630,\n",
       " 'finsish': 631,\n",
       " 'merc': 632,\n",
       " 'infiltr': 633,\n",
       " 'secret': 634,\n",
       " 'research': 635,\n",
       " 'lab': 636,\n",
       " 'locat': 637,\n",
       " 'tropic': 638,\n",
       " 'island': 639,\n",
       " 'warn': 640,\n",
       " 'scheme': 641,\n",
       " 'togeth': 642,\n",
       " 'along': 643,\n",
       " 'legion': 644,\n",
       " 'schmuck': 645,\n",
       " 'feel': 646,\n",
       " 'loneley': 647,\n",
       " 'invit': 648,\n",
       " 'three': 649,\n",
       " 'countrymen': 650,\n",
       " 'player': 651,\n",
       " 'name': 652,\n",
       " 'til': 653,\n",
       " 'schweiger': 654,\n",
       " 'udo': 655,\n",
       " 'kier': 656,\n",
       " 'ralf': 657,\n",
       " 'moeller': 658,\n",
       " 'self': 659,\n",
       " 'biz': 660,\n",
       " 'tale': 661,\n",
       " 'jack': 662,\n",
       " 'carver': 663,\n",
       " 'ye': 664,\n",
       " 'german': 665,\n",
       " 'hail': 666,\n",
       " 'bratwurst': 667,\n",
       " 'dude': 668,\n",
       " 'howev': 669,\n",
       " 'badass': 670,\n",
       " 'complain': 671,\n",
       " 'stay': 672,\n",
       " 'true': 673,\n",
       " 'whole': 674,\n",
       " 'perspect': 675,\n",
       " 'kick': 676,\n",
       " 'beyond': 677,\n",
       " 'dement': 678,\n",
       " 'evil': 679,\n",
       " 'mad': 680,\n",
       " 'scientist': 681,\n",
       " 'dr': 682,\n",
       " 'krieger': 683,\n",
       " 'genet': 684,\n",
       " 'mutat': 685,\n",
       " 'soldier': 686,\n",
       " 'gm': 687,\n",
       " 'top': 688,\n",
       " 'remind': 689,\n",
       " 'spoiler': 690,\n",
       " 'vancouv': 691,\n",
       " 'reason': 692,\n",
       " 'palm': 693,\n",
       " 'tree': 694,\n",
       " 'rich': 695,\n",
       " 'lumberjack': 696,\n",
       " 'wood': 697,\n",
       " 'gone': 698,\n",
       " 'start': 699,\n",
       " 'meheh': 700,\n",
       " 'shenanigan': 701,\n",
       " 'deliv': 702,\n",
       " 'mean': 703,\n",
       " 'suck': 704,\n",
       " 'impli': 705,\n",
       " 'area': 706,\n",
       " 'boat': 707,\n",
       " 'crome': 708,\n",
       " 'albino': 709,\n",
       " 'squad': 710,\n",
       " 'enter': 711,\n",
       " 'reek': 712,\n",
       " 'scheiss': 713,\n",
       " 'poop': 714,\n",
       " 'simpleton': 715,\n",
       " 'fa': 716,\n",
       " 'r': 717,\n",
       " 'take': 718,\n",
       " 'wiff': 719,\n",
       " 'ahead': 720,\n",
       " 'btw': 721,\n",
       " 'annoy': 722,\n",
       " 'sidekick': 723,\n",
       " 'shoot': 724,\n",
       " 'minut': 725,\n",
       " 'screen': 726,\n",
       " 'shakespear': 727,\n",
       " 'appreci': 728,\n",
       " 'mass': 729,\n",
       " 'scottish': 730,\n",
       " 'certain': 731,\n",
       " 'rev': 732,\n",
       " 'bowdler': 733,\n",
       " 'henc': 734,\n",
       " 'victorian': 735,\n",
       " 'era': 736,\n",
       " 'improv': 737,\n",
       " 'perfect': 738,\n",
       " 'ten': 739,\n",
       " 'text': 740,\n",
       " 'english': 741,\n",
       " 'composit': 742,\n",
       " 'fort': 743,\n",
       " 'keep': 744,\n",
       " 'cut': 745,\n",
       " 'fantast': 746,\n",
       " 'famou': 747,\n",
       " 'georg': 748,\n",
       " 'clooney': 749,\n",
       " 'roll': 750,\n",
       " 'man': 751,\n",
       " 'constant': 752,\n",
       " 'sorrow': 753,\n",
       " 'recommand': 754,\n",
       " 'everybodi': 755,\n",
       " 'greet': 756,\n",
       " 'bart': 757,\n",
       " 'kind': 758,\n",
       " 'drawn': 759,\n",
       " 'erot': 760,\n",
       " 'amateurish': 761,\n",
       " 'unbeliev': 762,\n",
       " 'sort': 763,\n",
       " 'school': 764,\n",
       " 'project': 765,\n",
       " 'rosanna': 766,\n",
       " 'arquett': 767,\n",
       " 'stock': 768,\n",
       " 'bizarr': 769,\n",
       " 'suppos': 770,\n",
       " 'midwest': 771,\n",
       " 'town': 772,\n",
       " 'involv': 773,\n",
       " 'lesson': 774,\n",
       " 'learn': 775,\n",
       " 'insight': 776,\n",
       " 'stilt': 777,\n",
       " 'ridicul': 778,\n",
       " 'lot': 779,\n",
       " 'skin': 780,\n",
       " 'intrigu': 781,\n",
       " 'videotap': 782,\n",
       " 'nonsens': 783,\n",
       " 'bisexu': 784,\n",
       " 'relationship': 785,\n",
       " 'nowher': 786,\n",
       " 'heterosexu': 787,\n",
       " 'absurd': 788,\n",
       " 'danc': 789,\n",
       " 'stereotyp': 790,\n",
       " 'pass': 791,\n",
       " 'million': 792,\n",
       " 'mile': 793,\n",
       " 'could': 794,\n",
       " 'spent': 795,\n",
       " 'starv': 796,\n",
       " 'aid': 797,\n",
       " 'africa': 798,\n",
       " 'simpli': 799,\n",
       " 'remad': 800,\n",
       " 'fail': 801,\n",
       " 'captur': 802,\n",
       " 'flavor': 803,\n",
       " 'terror': 804,\n",
       " '1963': 805,\n",
       " 'titl': 806,\n",
       " 'liam': 807,\n",
       " 'neeson': 808,\n",
       " 'excel': 809,\n",
       " 'alway': 810,\n",
       " 'hold': 811,\n",
       " 'except': 812,\n",
       " 'owen': 813,\n",
       " 'wilson': 814,\n",
       " 'luke': 815,\n",
       " 'major': 816,\n",
       " 'fault': 817,\n",
       " 'version': 818,\n",
       " 'stray': 819,\n",
       " 'shirley': 820,\n",
       " 'jackson': 821,\n",
       " 'attempt': 822,\n",
       " 'grandios': 823,\n",
       " 'thrill': 824,\n",
       " 'earlier': 825,\n",
       " 'trade': 826,\n",
       " 'snazzier': 827,\n",
       " 'special': 828,\n",
       " 'effect': 829,\n",
       " 'friction': 830,\n",
       " 'older': 831,\n",
       " 'horribl': 832,\n",
       " 'chanc': 833,\n",
       " 'busi': 834,\n",
       " 'run': 835,\n",
       " 'sword': 836,\n",
       " 'emot': 837,\n",
       " 'attach': 838,\n",
       " 'machin': 839,\n",
       " 'want': 840,\n",
       " 'destroy': 841,\n",
       " 'blatantli': 842,\n",
       " 'stolen': 843,\n",
       " 'lotr': 844,\n",
       " 'war': 845,\n",
       " 'matrix': 846,\n",
       " 'exampl': 847,\n",
       " 'ghost': 848,\n",
       " 'final': 849,\n",
       " 'yoda': 850,\n",
       " 'obe': 851,\n",
       " 'vader': 852,\n",
       " 'spider': 853,\n",
       " 'begin': 854,\n",
       " 'frodo': 855,\n",
       " 'attack': 856,\n",
       " 'return': 857,\n",
       " 'king': 858,\n",
       " 'elijah': 859,\n",
       " 'victim': 860,\n",
       " 'wait': 861,\n",
       " 'hypnot': 862,\n",
       " 'sting': 863,\n",
       " 'wrap': 864,\n",
       " 'uh': 865,\n",
       " 'hello': 866,\n",
       " 'vs': 867,\n",
       " 'termin': 868,\n",
       " 'someon': 869,\n",
       " 'nazi': 870,\n",
       " 'juvenil': 871,\n",
       " 'rush': 872,\n",
       " 'conclus': 873,\n",
       " 'adult': 874,\n",
       " 'either': 875,\n",
       " 'save': 876,\n",
       " 'rememb': 877,\n",
       " 'cinema': 878,\n",
       " 'dark': 879,\n",
       " 'nervou': 880,\n",
       " '74': 881,\n",
       " '75': 882,\n",
       " 'dad': 883,\n",
       " 'sister': 884,\n",
       " 'newburi': 885,\n",
       " 'berkshir': 886,\n",
       " 'england': 887,\n",
       " 'tiger': 888,\n",
       " 'snow': 889,\n",
       " 'appear': 890,\n",
       " 'grizzli': 891,\n",
       " 'adam': 892,\n",
       " 'dan': 893,\n",
       " 'haggeri': 894,\n",
       " 'anyon': 895,\n",
       " 'dvd': 896,\n",
       " 'etc': 897,\n",
       " 'pleas': 898,\n",
       " 'club': 899,\n",
       " 'shame': 900,\n",
       " 'nearest': 901,\n",
       " '20': 902,\n",
       " 'hear': 903,\n",
       " 'other': 904,\n",
       " 'stinker': 905,\n",
       " 'nomin': 906,\n",
       " 'golden': 907,\n",
       " 'globe': 908,\n",
       " 'femal': 909,\n",
       " 'renaiss': 910,\n",
       " 'painter': 911,\n",
       " 'mangl': 912,\n",
       " 'recognit': 913,\n",
       " 'complaint': 914,\n",
       " 'liberti': 915,\n",
       " 'perfectli': 916,\n",
       " 'fine': 917,\n",
       " 'account': 918,\n",
       " 'artist': 919,\n",
       " 'dishwat': 920,\n",
       " 'dull': 921,\n",
       " 'script': 922,\n",
       " 'enough': 923,\n",
       " 'nake': 924,\n",
       " 'factual': 925,\n",
       " 'hurriedli': 926,\n",
       " 'cap': 927,\n",
       " 'summari': 928,\n",
       " 'coupl': 929,\n",
       " 'hour': 930,\n",
       " 'favor': 931,\n",
       " 'breviti': 932,\n",
       " 'sequel': 933,\n",
       " 'surpris': 934,\n",
       " 'glut': 935,\n",
       " 'cash': 936,\n",
       " 'wrong': 937,\n",
       " 'guy': 938,\n",
       " 'concept': 939,\n",
       " 'cliffhang': 940,\n",
       " 'mountain': 941,\n",
       " 'rescu': 942,\n",
       " 'sli': 943,\n",
       " 'stop': 944,\n",
       " 'stallon': 945,\n",
       " 'nit': 946,\n",
       " 'picker': 947,\n",
       " 'especi': 948,\n",
       " 'expert': 949,\n",
       " 'climb': 950,\n",
       " 'aviat': 951,\n",
       " 'facial': 952,\n",
       " 'express': 953,\n",
       " 'full': 954,\n",
       " 'excus': 955,\n",
       " 'dismiss': 956,\n",
       " 'overblown': 957,\n",
       " 'pile': 958,\n",
       " 'junk': 959,\n",
       " 'hors': 960,\n",
       " 'lovabl': 961,\n",
       " 'undeni': 962,\n",
       " 'romp': 963,\n",
       " 'plenti': 964,\n",
       " 'john': 965,\n",
       " 'lithgow': 966,\n",
       " 'sneeri': 967,\n",
       " 'tick': 968,\n",
       " 'box': 969,\n",
       " 'baddi': 970,\n",
       " 'perman': 971,\n",
       " 'harass': 972,\n",
       " 'hapless': 973,\n",
       " 'turncoat': 974,\n",
       " 'agent': 975,\n",
       " 'rex': 976,\n",
       " 'linn': 977,\n",
       " 'traver': 978,\n",
       " 'henri': 979,\n",
       " 'rooker': 980,\n",
       " 'noteworthi': 981,\n",
       " 'cring': 982,\n",
       " 'worthi': 983,\n",
       " 'hal': 984,\n",
       " 'insist': 985,\n",
       " 'constantli': 986,\n",
       " 'shriek': 987,\n",
       " 'disbelief': 988,\n",
       " 'captor': 989,\n",
       " 'hurt': 990,\n",
       " 'anybodi': 991,\n",
       " 'whilst': 992,\n",
       " 'ralph': 993,\n",
       " 'frank': 994,\n",
       " 'grin': 995,\n",
       " 'girl': 996,\n",
       " 'plummet': 997,\n",
       " 'former': 998,\n",
       " 'london': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "eeea1906-ee6f-4bc6-800b-58553028bfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71513"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "dad2714f-1001-4821-9d4a-bed0cc1f172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Text to Indices Using\n",
    "\n",
    "def text_to_indices(text, vocab):\n",
    "    indexed_text = []  # Initialize an empty list to store numerical indices\n",
    "\n",
    "    # Tokenize the input text\n",
    "    for token in preprocess(text):  # Iterate over each token (word) in the tokenized text\n",
    "        if token in vocab:  # If the token is in the vocabulary\n",
    "            indexed_text.append(vocab[token])  # Append the corresponding index from vocab\n",
    "        else:  # If the token is not in the vocabulary\n",
    "            indexed_text.append(vocab['<UNK>'])  # Append the index for the <UNK> token\n",
    "\n",
    "    return indexed_text  # Return the list of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "90f23acb-6fd5-4e8a-90ff-9ef658a182e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the 'review' column\n",
    "df['encoded_review'] = df['review'].apply(lambda x: text_to_indices(x, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6a48e0aa-6c4b-438b-a495-0ccc95043bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>encoded_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, review, mention, watch, 1, oz, episod, h...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wonder, littl, product, br, br, film, techniq...</td>\n",
       "      <td>[136, 137, 138, 12, 12, 139, 140, 141, 142, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonder, way, spend, time, hot, summe...</td>\n",
       "      <td>[200, 136, 201, 202, 143, 203, 204, 205, 206, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basic, famili, littl, boy, jake, think, zombi...</td>\n",
       "      <td>[264, 265, 137, 266, 267, 268, 269, 270, 271, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, mattei, love, time, money, visual, st...</td>\n",
       "      <td>[304, 305, 238, 143, 306, 307, 308, 139, 4, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, movi, right, good, job, creativ, ori...</td>\n",
       "      <td>[200, 273, 9, 362, 1140, 4446, 494, 13, 292, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[bad, plot, bad, dialogu, bad, act, idiot, dir...</td>\n",
       "      <td>[483, 211, 483, 213, 483, 361, 3663, 363, 722,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[cathol, taught, parochi, elementari, school, ...</td>\n",
       "      <td>[7976, 10930, 7761, 9310, 764, 12202, 10930, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[go, disagre, previou, comment, side, maltin, ...</td>\n",
       "      <td>[22, 7281, 339, 513, 135, 5430, 1, 1472, 1143,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[one, expect, star, trek, movi, high, art, fan...</td>\n",
       "      <td>[1, 292, 506, 3910, 273, 57, 2317, 620, 292, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      One of the other reviewers has mentioned that ...  positive   \n",
       "1      A wonderful little production. <br /><br />The...  positive   \n",
       "2      I thought this was a wonderful way to spend ti...  positive   \n",
       "3      Basically there's a family where a little boy ...  negative   \n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  I thought this movie did a down right good job...  positive   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative   \n",
       "49997  I am a Catholic taught in parochial elementary...  negative   \n",
       "49998  I'm going to have to disagree with the previou...  negative   \n",
       "49999  No one expects the Star Trek movies to be high...  negative   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [one, review, mention, watch, 1, oz, episod, h...   \n",
       "1      [wonder, littl, product, br, br, film, techniq...   \n",
       "2      [thought, wonder, way, spend, time, hot, summe...   \n",
       "3      [basic, famili, littl, boy, jake, think, zombi...   \n",
       "4      [petter, mattei, love, time, money, visual, st...   \n",
       "...                                                  ...   \n",
       "49995  [thought, movi, right, good, job, creativ, ori...   \n",
       "49996  [bad, plot, bad, dialogu, bad, act, idiot, dir...   \n",
       "49997  [cathol, taught, parochi, elementari, school, ...   \n",
       "49998  [go, disagre, previou, comment, side, maltin, ...   \n",
       "49999  [one, expect, star, trek, movi, high, art, fan...   \n",
       "\n",
       "                                          encoded_review  \n",
       "0      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13...  \n",
       "1      [136, 137, 138, 12, 12, 139, 140, 141, 142, 14...  \n",
       "2      [200, 136, 201, 202, 143, 203, 204, 205, 206, ...  \n",
       "3      [264, 265, 137, 266, 267, 268, 269, 270, 271, ...  \n",
       "4      [304, 305, 238, 143, 306, 307, 308, 139, 4, 30...  \n",
       "...                                                  ...  \n",
       "49995  [200, 273, 9, 362, 1140, 4446, 494, 13, 292, 6...  \n",
       "49996  [483, 211, 483, 213, 483, 361, 3663, 363, 722,...  \n",
       "49997  [7976, 10930, 7761, 9310, 764, 12202, 10930, 4...  \n",
       "49998  [22, 7281, 339, 513, 135, 5430, 1, 1472, 1143,...  \n",
       "49999  [1, 292, 506, 3910, 273, 57, 2317, 620, 292, 2...  \n",
       "\n",
       "[50000 rows x 4 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f075d210-1547-44a6-94e9-9277cc1b5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {'positive': 1, 'negative': 0}\n",
    "df['Sentiment'] = df['sentiment'].map(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b45a4a8d-1071-49d6-92b7-ada8f3a27292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>encoded_review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, review, mention, watch, 1, oz, episod, h...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wonder, littl, product, br, br, film, techniq...</td>\n",
       "      <td>[136, 137, 138, 12, 12, 139, 140, 141, 142, 14...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonder, way, spend, time, hot, summe...</td>\n",
       "      <td>[200, 136, 201, 202, 143, 203, 204, 205, 206, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basic, famili, littl, boy, jake, think, zombi...</td>\n",
       "      <td>[264, 265, 137, 266, 267, 268, 269, 270, 271, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, mattei, love, time, money, visual, st...</td>\n",
       "      <td>[304, 305, 238, 143, 306, 307, 308, 139, 4, 30...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, movi, right, good, job, creativ, ori...</td>\n",
       "      <td>[200, 273, 9, 362, 1140, 4446, 494, 13, 292, 6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[bad, plot, bad, dialogu, bad, act, idiot, dir...</td>\n",
       "      <td>[483, 211, 483, 213, 483, 361, 3663, 363, 722,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[cathol, taught, parochi, elementari, school, ...</td>\n",
       "      <td>[7976, 10930, 7761, 9310, 764, 12202, 10930, 4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[go, disagre, previou, comment, side, maltin, ...</td>\n",
       "      <td>[22, 7281, 339, 513, 135, 5430, 1, 1472, 1143,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[one, expect, star, trek, movi, high, art, fan...</td>\n",
       "      <td>[1, 292, 506, 3910, 273, 57, 2317, 620, 292, 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      One of the other reviewers has mentioned that ...  positive   \n",
       "1      A wonderful little production. <br /><br />The...  positive   \n",
       "2      I thought this was a wonderful way to spend ti...  positive   \n",
       "3      Basically there's a family where a little boy ...  negative   \n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  I thought this movie did a down right good job...  positive   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative   \n",
       "49997  I am a Catholic taught in parochial elementary...  negative   \n",
       "49998  I'm going to have to disagree with the previou...  negative   \n",
       "49999  No one expects the Star Trek movies to be high...  negative   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [one, review, mention, watch, 1, oz, episod, h...   \n",
       "1      [wonder, littl, product, br, br, film, techniq...   \n",
       "2      [thought, wonder, way, spend, time, hot, summe...   \n",
       "3      [basic, famili, littl, boy, jake, think, zombi...   \n",
       "4      [petter, mattei, love, time, money, visual, st...   \n",
       "...                                                  ...   \n",
       "49995  [thought, movi, right, good, job, creativ, ori...   \n",
       "49996  [bad, plot, bad, dialogu, bad, act, idiot, dir...   \n",
       "49997  [cathol, taught, parochi, elementari, school, ...   \n",
       "49998  [go, disagre, previou, comment, side, maltin, ...   \n",
       "49999  [one, expect, star, trek, movi, high, art, fan...   \n",
       "\n",
       "                                          encoded_review  Sentiment  \n",
       "0      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13...          1  \n",
       "1      [136, 137, 138, 12, 12, 139, 140, 141, 142, 14...          1  \n",
       "2      [200, 136, 201, 202, 143, 203, 204, 205, 206, ...          1  \n",
       "3      [264, 265, 137, 266, 267, 268, 269, 270, 271, ...          0  \n",
       "4      [304, 305, 238, 143, 306, 307, 308, 139, 4, 30...          1  \n",
       "...                                                  ...        ...  \n",
       "49995  [200, 273, 9, 362, 1140, 4446, 494, 13, 292, 6...          1  \n",
       "49996  [483, 211, 483, 213, 483, 361, 3663, 363, 722,...          0  \n",
       "49997  [7976, 10930, 7761, 9310, 764, 12202, 10930, 4...          0  \n",
       "49998  [22, 7281, 339, 513, 135, 5430, 1, 1472, 1143,...          0  \n",
       "49999  [1, 292, 506, 3910, 273, 57, 2317, 620, 292, 2...          0  \n",
       "\n",
       "[50000 rows x 5 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "04939e69-c119-4d4f-89ca-87697aebe05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "64a9a09b-a885-4244-8261-f9be5c975f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, df, vocab):\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        numerical_review = text_to_indices(self.df.iloc[index]['review'], self.vocab)\n",
    "        sentiment_label  = self.df.iloc[index]['sentiment']\n",
    "\n",
    "        sentiment = 1 if sentiment_label == \"positive\" else 0  # Keep sentiment as int (not tensor)\n",
    "\n",
    "        return numerical_review, sentiment  # Return list (not tensor) to be handled by collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2b9f3382-6a7c-4171-aa64-7e2ce6c7644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = MovieDataset(df, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c721723b-cf09-4b8c-aa95-051f14bea807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "cd326a96-94e0-4a9e-836d-6e62e57532e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    reviews, sentiments = zip(*batch)  # Unzip batch into reviews and sentiments\n",
    "\n",
    "    # Convert each review (list) into a tensor\n",
    "    reviews = [torch.tensor(r, dtype=torch.long) for r in reviews]\n",
    "\n",
    "    # Pad sequences to the same length\n",
    "    padded_reviews = pad_sequence(reviews, batch_first=True, padding_value=0)\n",
    "\n",
    "    # Convert sentiments list into a tensor\n",
    "    sentiments = torch.tensor(sentiments, dtype=torch.long)\n",
    "\n",
    "    return padded_reviews, sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "76b63477-8643-4a40-bb54-f9360b4a94d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset = MovieDataset(df, vocab)\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "19aed17e-c701-4a3c-84f7-7b0736a1d873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 364])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Example: Fetch one batch\n",
    "for batch in train_loader:\n",
    "    reviews, sentiments = batch\n",
    "    print(reviews.shape)  # (batch_size, max_seq_len)\n",
    "    print(sentiments.shape)  # (batch_size,)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "52adaa0d-be5b-4fff-b063-b3d9d460bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "463d7b38-6e78-478d-959b-a9a3482f432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim=50)\n",
    "        self.rnn = nn.RNN(50, 128, batch_first=True)\n",
    "        self.fc = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, review):\n",
    "        embedding_review = self.embeddings(review)\n",
    "        hidden, final = self.rnn(embedding_review)\n",
    "        output = self.fc(final[-1])  # final_hidden[-1] has shape (batch_size, hidden_dim)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0fa40e7a-1c99-4ff6-a954-bf42b6e6b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRNN(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "acd090f9-e47e-4b13-8b0f-e6c1d699ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "5eac5678-637f-4364-8587-599981997417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1091.9156\n",
      "Epoch: 2, Loss: 1091.1613\n",
      "Epoch: 3, Loss: 1092.4059\n",
      "Epoch: 4, Loss: 1091.8880\n",
      "Epoch: 5, Loss: 1090.3075\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for review, sentiment in train_loader:\n",
    "        sentiment = sentiment.long()  # Fix Issue 1 (Remove squeeze)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(review)  # Shape: (batch_size, 2)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(output, sentiment)  # Fix Issue 2 (Ensure sentiment is correct shape)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item()  # Fix Issue 3 (Use +=)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "90f81263-78e7-49ae-870b-cfe69c7545e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 50.12%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for feature, labels in train_loader:\n",
    "        # feature, labels = feature.to(device), labels.to(device)\n",
    "        outputs = model(feature)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b2e08d06-5c0b-4bf7-ae0b-cf61bfe2932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, review, vocab, threshold=0.4):\n",
    "    # Convert text to numerical indices\n",
    "    numerical_review = text_to_indices(review, vocab)\n",
    "\n",
    "    # Convert to tensor and reshape for batch dimension\n",
    "    review_tensor = torch.tensor(numerical_review, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    # Get model predictions\n",
    "    output = model(review_tensor)\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    probs = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "    # Get the max probability and corresponding sentiment index\n",
    "    confidence, index = torch.max(probs, dim=1)\n",
    "\n",
    "    # Convert tensor to float value\n",
    "    confidence = float(confidence.item())\n",
    "\n",
    "    print(\"confidence: \", confidence)\n",
    "\n",
    "    # If confidence is too low, return \"I don't know\"\n",
    "    if confidence < threshold:\n",
    "        return \"I don't know\"\n",
    "\n",
    "    # Convert index to sentiment label\n",
    "    sentiment_label = \"positive\" if index.item() == 1 else \"negative\"\n",
    "\n",
    "    return sentiment_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "594526a5-854a-4ed1-9562-33f175933947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence:  0.5656965374946594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"moview was good\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "7f6c0a52-d8b2-456b-a744-7a9138abffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(model, review, vocab, threshold=0.5):\n",
    "#     # Convert text to numerical indices\n",
    "#     numerical_review = text_to_indices(review, vocab)\n",
    "\n",
    "#     # Convert to tensor and reshape for batch dimension\n",
    "#     review_tensor = torch.tensor(numerical_review, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "#     # Get model predictions (logits)\n",
    "#     output = model(review_tensor)\n",
    "\n",
    "#     # Convert logits to probabilities\n",
    "#     probs = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "#     # Get the max probability and corresponding sentiment index\n",
    "#     confidence, index = torch.max(probs, dim=1)\n",
    "\n",
    "#     # Convert tensor to float\n",
    "#     confidence = float(confidence.item())\n",
    "\n",
    "#     # 🔄 Flip the prediction\n",
    "#     flipped_index = 1 - index.item()  # If 0 → 1, if 1 → 0\n",
    "\n",
    "#     # Print debugging info\n",
    "#     print(\"Raw Output (logits):\", output)\n",
    "#     print(\"Softmax Probabilities:\", probs)\n",
    "#     print(\"Predicted Index:\", index.item())\n",
    "#     print(\"Confidence:\", confidence)\n",
    "\n",
    "#     # If confidence is too low, return \"I don't know\"\n",
    "#     if confidence < threshold:\n",
    "#         return \"I don't know\"\n",
    "\n",
    "#     # Convert index to sentiment label\n",
    "#     sentiment_label = \"positive\" if flipped_index == 1 else \"negative\"\n",
    "\n",
    "#     return sentiment_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "fcd128c0-93ae-4bd5-b6a4-16bb78f028be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence:  0.5656965374946594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"moview was good\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "2103ac0e-a022-4291-84f6-3f4d7f3cb064",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"While films like Parmanu, Padmavati, Padman, Sonu Ke Titu Ki Sweety , 102 Not Out, Hichki or even Blackmail were treat to eyes in the first half of 2018 giving hope that Bollywood movies have matured but then there comes a crap like Race 3 that will spoil your mood and you will wonder that if the makers are taking the audience for granted.\n",
    "\n",
    "Race 3 tells the story of a dispute between a family when Shamsher Singh (Anil Kapoor) decides to give half of his wealth to the adopted son, Sikander Singh (Salman Khan) and the rest of it between his own kids, Suraj (Saqeeb Saleem) and Sanjana (Daisy Shah).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "22cbfba8-4a21-4a54-9107-a9c94f857db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence:  0.5106473565101624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, review, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5cc866c8-73b2-421b-9fa7-68ffc924b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"\n",
    "I don't know what kind of mental conditions these people are suffering from, who are rating this movie 10/10. Why couldn't they just make it simple why this whole addition of crap. Just another crappy amalgamation of the movies which had a better script. \n",
    "I just don't think Salman will make any sensible movies in which he just acts good and doesn't just say mindless dialogues.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "daa833d3-7258-4831-8ebe-e56fb5ff3d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence:  0.5202184319496155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, review, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c8a9c7-3a33-4b58-a9f9-5f3e8d176f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
